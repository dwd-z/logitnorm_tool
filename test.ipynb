{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_name: cifar10_wrn_logitnorm_standard\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "from datasets.utils import build_dataset, get_ood_dataloaders\n",
    "from models.utils import build_model\n",
    "from utils.eval import *\n",
    "from utils.loss import LogitNormLoss\n",
    "\n",
    "\n",
    "gpu = 0         # gpu id, use cpu if None\n",
    "seed = 1        # random seed\n",
    "num_to_avg = 10 # number of trials with random images in OOD datasets to calculate the average performance scores\n",
    "\n",
    "model_type = 'wrn'          # model name\n",
    "loss_function = 'logitnorm'    # loss function 'normal' 'logitnorm'\n",
    "dataset =  'cifar10'        # training dataset\n",
    "\n",
    "# file name to save the weights and training infomation\n",
    "method_name = '_'.join([dataset, model_type, loss_function, 'standard'])\n",
    "print(\"method_name: \" + method_name)\n",
    "\n",
    "score_function = 'energy'   # post-hoc score function used for OOD detection\n",
    "test_bs = 200 # 200       # batch size for training and testing \n",
    "num_classes = 10    # number of classes of the training dataset\n",
    "input_size = 32     # input image size for the model\n",
    "input_channels = 3  # number of input image channels for the model\n",
    "mean=(0.492, 0.482, 0.446) # mean value for normalization of input images\n",
    "std=(0.247, 0.244, 0.262)  # standard deviation for normalization of input images\n",
    "prefetch_threads = 4       # number of threads used for input image preprocessing\n",
    "save_path = './snapshots/' # folder path to save the weights and training information\n",
    "\n",
    "if loss_function == 'normal':\n",
    "    init_temp = 1.5\n",
    "elif loss_function == 'logitnorm':\n",
    "    init_temp = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "could not resume",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5241/777240764.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Create model and load weights from .pt file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/logitnorm_tool/models/utils.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(model_type, num_classes, device, load, path, filename)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"could not resume\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: could not resume"
     ]
    }
   ],
   "source": [
    "# initiate the device\n",
    "# if gpu is not None:\n",
    "#     device = torch.device('cuda:{}'.format(int(gpu)))\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "# else:\n",
    "#     device = torch.device('cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Create model and load weights from .pt file\n",
    "net = build_model(model_type, num_classes, device, load=True, path=save_path, filename=method_name)\n",
    "\n",
    "net.eval()\n",
    "cudnn.benchmark = True  # fire on all cylinders\n",
    "\n",
    "# load ID test dataset\n",
    "test_data = build_dataset(dataset, mode=\"test\", size=input_size, channels=input_channels,\n",
    "                          mean=mean, std=std)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=test_bs, shuffle=False,\n",
    "                                          num_workers=prefetch_threads, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ood_num_examples: 2000\n",
      "Error Rate 5.50\n",
      "\t\t\t\tcifar10_wrn_logitnorm_standard\n",
      "FPR95:\t\t\t65.09\n",
      "AUROC: \t\t\t87.35\n",
      "AUPR:  \t\t\t99.14\n",
      "\n",
      "\n",
      "ECE Error\n",
      "ECE Error 1.43\n",
      "\n",
      "\n",
      "Textures Detection\n",
      "\t\t\t\tcifar10_wrn_logitnorm_standard\n",
      "FPR95:\t\t\t94.44\t+/- 0.55\n",
      "AUROC: \t\t\t62.99\t+/- 0.42\n",
      "AUPR:  \t\t\t69.83\t+/- 0.43\n",
      "\n",
      "\n",
      "SVHN Detection\n",
      "\t\t\t\tcifar10_wrn_logitnorm_standard\n",
      "FPR95:\t\t\t99.47\t+/- 0.11\n",
      "AUROC: \t\t\t65.00\t+/- 0.25\n",
      "AUPR:  \t\t\t76.23\t+/- 0.14\n",
      "\n",
      "\n",
      "LSUN-C Detection\n",
      "\t\t\t\tcifar10_wrn_logitnorm_standard\n",
      "FPR95:\t\t\t99.30\t+/- 0.19\n",
      "AUROC: \t\t\t60.21\t+/- 0.42\n",
      "AUPR:  \t\t\t71.71\t+/- 0.23\n",
      "\n",
      "\n",
      "LSUN-R Detection\n",
      "\t\t\t\tcifar10_wrn_logitnorm_standard\n",
      "FPR95:\t\t\t99.21\t+/- 0.11\n",
      "AUROC: \t\t\t74.04\t+/- 0.26\n",
      "AUPR:  \t\t\t82.15\t+/- 0.21\n",
      "\n",
      "\n",
      "iSUN Detection\n",
      "\t\t\t\tcifar10_wrn_logitnorm_standard\n",
      "FPR95:\t\t\t99.51\t+/- 0.10\n",
      "AUROC: \t\t\t71.96\t+/- 0.21\n",
      "AUPR:  \t\t\t80.91\t+/- 0.13\n",
      "\n",
      "\n",
      "Places365 Detection\n",
      "\t\t\t\tcifar10_wrn_logitnorm_standard\n",
      "FPR95:\t\t\t87.26\t+/- 0.48\n",
      "AUROC: \t\t\t78.22\t+/- 0.35\n",
      "AUPR:  \t\t\t81.39\t+/- 0.28\n",
      "\n",
      "\n",
      "Mean Test Results\n",
      "\t\t\t\tcifar10_wrn_logitnorm_standard\n",
      "FPR95:\t\t\t96.53\n",
      "AUROC: \t\t\t68.74\n",
      "AUPR:  \t\t\t77.04\n"
     ]
    }
   ],
   "source": [
    "# load OOD test datasets\n",
    "ood_num_examples = len(test_data) // 5\n",
    "print('ood_num_examples:', ood_num_examples)\n",
    "ood_data_list = [\"Textures\", \"SVHN\", 'LSUN-C', 'LSUN-R', \"iSUN\", \"Places365\"] # name of OOD datasets to load\n",
    "ood_loader_dict = get_ood_dataloaders(ood_data_list, input_size=input_size, input_channels=input_channels, \n",
    "                                      mean=mean, std=std, test_bs=test_bs, prefetch_threads=prefetch_threads,\n",
    "                                      seed=seed)\n",
    "\n",
    "# get and print all the ID and OOD detection performance measures of the model\n",
    "error_rate, ece_error, auroc, aupr, fpr, auroc_list, aupr_list, fpr_list = get_all_measures(\n",
    "    net, test_loader, ood_loader_dict, device, temp=0.1, init_temp=init_temp, score_function=score_function, \n",
    "    recall_level=0.95, ood_num_examples=ood_num_examples, test_bs=test_bs, to_string=True, num_to_avg=num_to_avg,\n",
    "    method_name=method_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
